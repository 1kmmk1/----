{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a111f3b",
   "metadata": {},
   "source": [
    "# [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215v3)\n",
    "- 그 유명한 seq2seq\n",
    "- 어떤 내용일까. 간략하게 요약.\n",
    "\n",
    "## Abstract\n",
    "- 2개의 깊은(multi-layered) LSTM을 어떻게 사용하는지 보여준다.\n",
    "    - 하나는 입력 문장을 고정된 차원의 벡터로 만들고(Encoder)\n",
    "    - 다른 하나는 그 벡터로부터 target sequence를 출력한다.(Decoder)\n",
    "---\n",
    "- LSTM은 긴 문장을 학습하는데 어려움이 없고 민감한(sensible) 구나 문장 표현을 학습할 수 있다.\n",
    "- 본 논문에서는 입력 문장의 단어 순서를 뒤집어서 LSTM의 성능을 markedly(눈에 띄게)향상시킬 수 있는 새로운 방법을 제시한다.\n",
    "    - 단어 순서를 뒤집는 것이 더 좋은 명확한(정확한) 이유는 보일 수 없지만 그렇게 하는것이 source와 target의 단기의존성을 많이 제공하여, 최적화 문제를 더 간단하게 만들었다고 설명할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271b86d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- DNN(Dense Neural Networks)의 장점\n",
    "    1. 병렬 계산 가능(parallel computation)\n",
    "    2. 복잡한 계산 가능(intricate computation)\n",
    "    3. 역전파(labeling된 데이터가 있을 때의 supervised backpropagation)\n",
    "---\n",
    "- DNN의 단점\n",
    "    1. Input과 target이 고정된 차원의 벡터로 인코딩 될 수 있는 문제만 사용 가능.\n",
    "    - 하지만 현실에서는 sequence의 길이를 예측할 수 없음.\n",
    "    - 그래서 **domain independent**한 seq2seq가 더 유용할 것이다.\n",
    "---\n",
    "#### 핵심 아이디어\n",
    "1. 하나의 LSTM이 input sequence를 읽고 고정된 차원의 벡터 표현으로 바꾼다.\n",
    "2. 다른 LSTM이 그 벡터 표현으로부터 output sentence를 추출(extract)한다.\n",
    "- LSTM은 다른 시계열 모델보다 장기의존관계를 학습할 능력이 있기 때문에 사용하였다.\n",
    "---\n",
    "#### key technical contributions\n",
    "- 입력 문장(source sentence)의 단어들의 순서를 뒤집음으로써 최적화 문제를 간단히 하여 학습을 용이하게 하였다.\n",
    "- LSTM은 다양한 길이의 입력 문장을 고정된 차원의 벡터 표현으로 바꿀 수 있다는 점을 활용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba76851",
   "metadata": {},
   "source": [
    "## 2. The model\n",
    "- input과 output의 길이가 다른 경우 어떻게 RNN을 적용할 수 있나?<br><br>\n",
    "바로 2개의 RNN을 사용함으로써 그 문제를 해결할 수 있다.<br><br>\n",
    "- 이러한 접근법(Encoder & Decoder)은 이미 전에 수행되었음.\n",
    "---\n",
    "#### 이 논문이 이전의 연구와 다른 점은?\n",
    "1. 2개의 다른 LSTM을 사용하였다.\n",
    "2. Deep LSTM(여러 층으로 구성된 LSTM) shallow LSTM보다 더 좋은 성능을 보이는 것을 확인하여, deep LSTM을 사용하였다.\n",
    "3. 입력 문장의 단어 순서를 뒤집었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61119421",
   "metadata": {},
   "source": [
    "## 3. Experiments\n",
    "- WMT'14 English to French MT task에 2가지 방법으로 적용하였다.\n",
    "    1. SMT system에 대한 참고(reference)없이 바로 입력 문장을 해석.\n",
    "    2. SMT baseline의 n-best lists를 rescore하였다.\n",
    "        - 이건 무슨 뜻인지 정확히 모르겠음.\n",
    "---\n",
    "### 3-1. Dataset details\n",
    "- 348M 개의 불어 단어와 304M개의 영어단어를 포함하는 12M개의 문장을 학습 데이터로 사용하였다. \n",
    "    - 이런 학습 데이터셋을 선택한 이유: n-best list & public availability\n",
    "- 전형적인 neural language model은 각 단어의 벡터 표현에 의존하는 반면, 우리의 모델은 두 언어의 고정된 단어를 사용하였다.(고정된 단어의 개수)\n",
    "    - 16만개의 source language 단어와 8만개의 target language 단어.\n",
    "    - OOV 단어는 <\"UNK\"> token으로 대체됨.\n",
    "---\n",
    "### 3-2. Decoding and Rescoring\n",
    "- source sentence가 주어졌을 때 정확한 해석 T에 대한 로그 가능도를 '최대화'하는 방식으로 학습을 진행하였다. \n",
    "    - 따라서, 목적 함수(objective function): ${1 \\over |{\\bf S}|} \\sum_{(T,S) \\in {\\bf S}} \\log p(T|S)$\n",
    "        - $\\bf S$는 훈련집합(training set)이다.\n",
    "    - 훈련 1 EPOCH 종료 --> 다음 식에 따라LSTM에서 가장 그럴싸한(가능성 높은?) 해석을 출력한다. $\\rightarrow \\hat T = \\arg \\max_Tp(T|S)$\n",
    "---\n",
    "#### 어떻게 가장 그럴싸한 해석(the most likely translation)을 찾을까?\n",
    "- **Beam Search**를 사용한다. \n",
    "- ※참고※ Beam Search에 대한 간단한 설명\n",
    "    - Greedy searching을 보완한 기법.  누적확률분포를 고려하여  미리 설정한 beam size(k)만큼 선택한다. 자세한 것은 구글링,,,\n",
    "- 이 논문에서는 beam size가 1일때도 seq2seq 모델은 잘 작동하며, beam size가 2일때 높은 성능을 보인다.(사실 12일 때 가장 높은 성능이지만, 연산량을 고려했을 때, 2로 하는것이 훨씬 효율적이라서 provide most of the benefits of beam search라고 적어 놓은 것 같음)\n",
    "- baseline system에 의해 생성된 [1000-best lists를 rescore 한다]().\n",
    "    - LSTM이 산출한 모든 가설(hypothesis)에 대한 로그 가능도를 계산하고 단순평균?(even average)을 계산한다.\n",
    "        - even average는 무엇으로 해석,,?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b127aff",
   "metadata": {},
   "source": [
    "### 3-3. Reversing the Source Senetences\n",
    "- sourece 문장의 단어 순서가 뒤바뀌면(reversed) LSTM 훨씬 더 잘 학습한다는 것을 확인하였다.\n",
    "    - test data에 대한 perplexity가 5.8에서 4.7로 감소하였고\n",
    "    - BLEU score가 25.9에서 30.6으로 증가하였다.\n",
    "- 본 논문에서는 이러한 현상에 대해 완벽한 설명은 제공하지 못한다. **'introduction of many short term dependencies'** 때문일 것이라고 생각한다.\n",
    "    - source가 target으로 해석될 때, target문장에 대응하는 source 문장의 단어들은 target과 주로 멀리 떨어져있게 된다. 이것은 결과적으로 **['large minimal time lag'](https://proceedings.neurips.cc/paper/1996/file/a4d2f0d23dcc84ce983ff9157f8b7f88-Paper.pdf)**문제를 일으킨다.\n",
    "    - Reversing해도 대응하는 단어들의 평균 거리는 바뀌지 않는다.\n",
    "    - 하지만 첫 몇개의 source 단어는 target 단어와 굉장히 가까워지고 'minimal time lag'문제가 급격하게 줄어든다.\n",
    "        - 그러므로 역전파를 통한 'establishing communication'이 더 용이하다.(source와 target사이)\n",
    "    - 결과적으로 Reversing하는 것은 긴 문장을 학습하는데 효과적이다.(better memory utilization) \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44952cc1",
   "metadata": {},
   "source": [
    "### 3-4. Training details\n",
    "- 1000개의 hidden cell(임베딩 차원도 1000)\n",
    "- 4개의 LSTM층 사용 \n",
    "    - Deep LSTM이 shallow보다 더 좋은 성능.\n",
    "    - 하나 추가할 때마다 perlexity 10%정도 감소.\n",
    "- input vocab은 16만개, output vocab은 8만개(고정)\n",
    "- 결과적으로 384M개의 학습 파라미터\n",
    "    - 64M개의 순환연결(32M Encoder, 32M Decoder)\n",
    "1. 가중치 초기화: LSTM의 가중치를 -0.08~0.08사이의 균등 분포에 따라 초기화\n",
    "2. momentum 없는 SGD 사용. 학습률은 처음에 0.7로 고정. 5 Epoch 이후부터는 epoch절반마다 학습률을 반으로 줄였다.\n",
    "3. 배치 사이즈: 128. Gradient를 배치사이즈로 나눠주었음.\n",
    "4. LSTM에도 가중치 폭발 문제가 여전히 존재했기 때문에, 임계값을 넘을 시 scaling 해주었다. \n",
    "    - l2 norm을 계산하였고, 임계값(5)을 넘으면 $g = {5g \\over s}, \\space (s = ||g||_2)$로 scaling 해주었다.\n",
    "5. 대부분의 문장은 짧고 긴 문장은 거의 없었다. 미니배치가 랜덤으로 선택되어서, 많은 minibatch는 연산량을 낭비했음. 따라서 모든 minibatch의 문장들이 같은 길이를 가지도록 하였고 결과적으로 2배의 속도를 얻었다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2bc31",
   "metadata": {},
   "source": [
    "### 3-5. Parallelization\n",
    "- DNN의 장점 중 하나.\n",
    "- 하나의 GPU는 초당 1,700개 단어 연산 \n",
    "    - 너무 느려서 8개의 GPU를 사용하였다.\n",
    "        - 4개는 LSTM층 연산에 사용하고 남은 4개는 softmax를 병렬화 하는데 사용하였다.\n",
    "        - 그래서 각 GPU는 1000 x 2000 크기의 행렬을 계산하였음.\n",
    "- 결과적으로 배치사이즈 128에서 초당 영어와 불어 각각 6,300단어씩 연산을 수행할 수 있었다.\n",
    "    - 학습하는데 10일이 걸렸다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415785a",
   "metadata": {},
   "source": [
    "### 3-6. Experimental Results\n",
    "- 번역의 질을 평가하는데 BLEU score를 사용하였다. \n",
    "- 결과표는 해당 논문에서 확인할 수 있다. \n",
    "- 1000 best list를 rescoring 하고 5개의 reversed LSTM을 사용했을 때, best WMT'14 score와 0.5 차이.(best WMT'14: 37, seq2seq:36.5)\n",
    "---\n",
    "### 3-7. Performance on long sentences\n",
    "### 3-8. Model Analysis\n",
    "- Test 결과 몇개 보여줌.\n",
    "- PCA 차원축소로 유사한 문장들은 유사한 위치를 가진다는 것을 보여줌..?\n",
    "---\n",
    "## 4. Related work\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb08ff3",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Conclusion \n",
    "- Deep LSTM의 높은 성능 확인\n",
    "- Reversed 훈련 방식의 높은 성능 확인.\n",
    "- reversede dataset으로 학습된 LSTM이 긴 문장을 번역하는 데 큰 어려움이 없음을 확인.\n",
    "- 직관적이고, 간단하고 비교적 덜 최적화된 접근방식이 SMT system을 능가했다는 것을 보여주었음.\n",
    "    - 무슨 의미,,?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d514b2d",
   "metadata": {},
   "source": [
    "### [seq2seq 구현](https://github.com/farizrahman4u/seq2seq/blob/master/seq2seq/models.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08782ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#경로 바꿔주기\n",
    "import os\n",
    "path = 'C:/Users/alsrl/밑바닥부터 시작하는 딥러닝_2/ch07'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e4a281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\alsrl\\\\밑바닥부터 시작하는 딥러닝_2\\\\ch07'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#현재 경로 확인\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b84d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab1cadc",
   "metadata": {},
   "source": [
    "### Framework를 사용하지 않는 naive한 구현(by 밑바닥2)\n",
    "- 더하기 문제 구현하기\n",
    "###### 1. Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "428bbaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size): #vocab_size: 어휘 수(문자의 종류)\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        \n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful = False) #LSTM이 계층 상태를 유지하지 않으므로 False \n",
    "        \n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :] #Encoder의 출력: 은닉상태에서 마지막 time step의 값\n",
    "    \n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh \n",
    "        \n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed1e904",
   "metadata": {},
   "source": [
    "##### 코드 뜯어보기 ① Encoder\n",
    "```python\n",
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "```\n",
    "- vocab_size: 문자(단어)의 종류. \n",
    "- wordvec_size: embedding된 문자(단어)벡터의 차원 수.\n",
    "- hidden_size: LSTM 계층에서 은닉 상태 벡터의 차원 수\n",
    "---\n",
    "```python\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "```\n",
    "- 가중치 초기화 방식. \n",
    "    - 임베딩 할 때 사용되는 가중치들은 100으로 정규분포를 100으로 나누어서 초기화\n",
    "    - 입력 가중치는 임베딩 벡터의 우너 수의 제곱근으로 나누어 초기화.\n",
    "    - 은닉 상태의 가중치는 은닉 벡터 차원 수의 제곱근으로 나누어 초기화.\n",
    "---\n",
    "```python\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful = False) #LSTM이 계층 상태를 유지하지 않으므로 False \n",
    "```\n",
    "- 각 층을 만들어준다. \n",
    "    - TimeEmbedding과 TimeLSTM은 책에서 사용하는 임베딩, LSTM 층의 이름\n",
    "        - stateful = False --> 은닉상태 유지할 필요 없기 때문에\n",
    "---\n",
    "```python\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "```\n",
    "- 리스트 들의 합이다.(self.embed.params는 list형태 self.lstm.params 또한 리스트 형태임)\n",
    "    - grads 또한 전부 기울기 형태로, 다 더해서 하나의 params list와 grads list에 저장해둔다.\n",
    "---\n",
    "```python\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :]\n",
    "```\n",
    "- forward는 xs를 입력으로 받아 embeding 층과 lstm층을 차례로 통과시킨다\n",
    "    - lstm층을 통과한 hs는 self.hs에 저장된다. \n",
    "    - Encoder는 입력을 하나의 고정된 벡터로 출력하는 것을 목표로 하기 때문에 forward의 출력은 hs(은닉층)의 마지막 time step 값이다.\n",
    "---\n",
    "```python\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh \n",
    "        \n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout \n",
    "```\n",
    "- backward때는 입력으로 받은(손실함수로 계산된 값) dh를, dhs[:, -1, :]에 저장한다.\n",
    "    - dhs는 hs와 같은 shape을 가진 영텐서임.\n",
    "    - backward의 결과값 dout를 return한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011105c3",
   "metadata": {},
   "source": [
    "###### 2. Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2263020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size): #vocab_size: 어휘 수(문자의 종류)\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b =  np.zeros(V).astype('f')\n",
    "        \n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful = False) \n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "        \n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(h)\n",
    "        \n",
    "        out = self.embed.forward(xs)\n",
    "        out = self.lstm.forward(out)\n",
    "        score = self.affine.forward(out)\n",
    "        return score\n",
    "    \n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dout = self.embed.backward(dout)\n",
    "        dh = self.lstm.dh\n",
    "        return dh\n",
    "    \n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        self.lstm.get_state(h)\n",
    "        \n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape((1,1))\n",
    "            out = self.embed.forward(x)\n",
    "            out = self.lstm.forward(out)\n",
    "            score = self.affine.forward(out)\n",
    "            \n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(int(sample_id))\n",
    "            \n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde98a3d",
   "metadata": {},
   "source": [
    "###### 코드 뜯어보기 ② Decoder\n",
    "- Encoder와 거의 유사함\n",
    "```python\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "```\n",
    "- Affine연결 층이 있다는 것을 제외하면 거의 비슷.\n",
    "--- \n",
    "- forward(순전파)에서는 xs와 은닉벡터(h) 2개를 입력으로 받는다.\n",
    "---\n",
    "```python\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        self.lstm.get_state(h)\n",
    "        \n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape((1,1))\n",
    "            out = self.embed.forward(x)\n",
    "            out = self.lstm.forward(out)\n",
    "            score = self.affine.forward(out)\n",
    "            \n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(int(sample_id))\n",
    "            \n",
    "        return sampled\n",
    "```\n",
    "- 입력을 받으면 Affine 층의 출려에서 가장 큰 id를 선택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a7c31",
   "metadata": {},
   "source": [
    "##### 3. Encoder/Decoder 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33704efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "class Seq2seq(BaseModel):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "        \n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "        \n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "        h = self.encoder.forward(xs)\n",
    "        score = self.decoder.forward(decoder_xs, h)\n",
    "        loss = self.softmax.forward(score, decoder_ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout = 1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n",
    "    \n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.encoder.forward(xs)\n",
    "        sampled = self.decoder.generat(h, start_id, sample_size)\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f78556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437bb7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1be7919",
   "metadata": {},
   "source": [
    "#### Pytorch를 이용한 Encoder & Decoder 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b6ae48",
   "metadata": {},
   "source": [
    "### 1. Encoder\n",
    "- 문자열을 받아서 고정된 길이의 벡터로 출력\n",
    "- 모든 층은 LSTM으로 구성된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1b9078",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'recurrentshop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrecurrentshop\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrecurrentshop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcells\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'recurrentshop'"
     ]
    }
   ],
   "source": [
    "class LSTMDecoderCell(ExtendedRNNCell):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b02e4",
   "metadata": {},
   "source": [
    "### 2. Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca3174b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c3e6cc6",
   "metadata": {},
   "source": [
    "### 3. Seq2Seq \n",
    "- Encoder과 Decoder를 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c34919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp1",
   "language": "python",
   "name": "nlp1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
