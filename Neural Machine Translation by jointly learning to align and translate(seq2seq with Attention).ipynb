{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a36f482",
   "metadata": {},
   "source": [
    "# NMT by jointly learning to align and translate(seq2seq with Attention)\n",
    "- 논문코드(papers with code)\n",
    "- [여기](https://github.com/graykode/nlp-tutorial)에 NLP tutorial이 엄청 자세하게 나와있다 + 논문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199777a",
   "metadata": {},
   "source": [
    "### 논문 내용 요약\n",
    "- 기존의 RNN encoder-decoder 모델에 어떤 메커니즘(attention)을 추가한 모델을 제시한다.\n",
    "---\n",
    "## 1. Introduction\n",
    "- NMT자체가 새로운 접근법이다.\n",
    "    - 하나의 신경망을 학습시켜 기계 번역을 한다는 접근이 새롭게 떠오르는 방법이다.\n",
    "- 지금까지 제시된 대부분의 NMT모델은 Encoder-Decoder 구조를 가진다.\n",
    "    - Encoder가 입력 문장을 하나의 고정된 길이의 벡터로 encode한다.\n",
    "    - Decoder는 그벡터를 가지고 번역을 생성한다.\n",
    "- 가장 큰 문제는 Encoder가 입력 문장을 **고정된 길이의 벡터**로 바꾼다는 것이다.\n",
    "    - 긴 문장이든 짧은 문장이든 어떤 고정된 길이의 벡터로 바꾸면, 그만큼 모델이 제 기능을 못할 가능성이 있다.\n",
    "    - 실제로 입력 문장이 길어질수록 기존의 Encoder-Decoder 모델은 성능이 빠르게 저하된다.\n",
    "- 따라서 본 연구는 align과 translate을 동시에 학습하는 모델을 제시한다.\n",
    "    1. target이 예측될 때 source에서 어떤 부분을 참고하였는지에 대한 '관계성'(alignment)을 학습한다.\n",
    "    2. 동시에 Translate 또한 학습.\n",
    "    - 기존 모델이 가졌던 문제를 타파.\n",
    "        - 즉, 고정된 길이의 벡터로 인코딩 하지 않는다.\n",
    "        - 여러게의 벡터 시퀀스로 인코딩 하고 이 시퀀스들의 부분집합을 선택하여 target을 예측하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c1a9c",
   "metadata": {},
   "source": [
    "## 2. Background: NMT\n",
    "- 결국 NMT나 SMT 모두 입력 문장 x에 대한 출력 문장 y의 조건부 확률을 최대화 하는 방향을 추구한다.\n",
    "    - NMT에서는 문장 쌍을 이용하여 조건부 확률 분포를 찾고 분포에서 값을 최대화 하는 target을 선택하는 방식으로 학습이 진행된다. \n",
    "    - 이전 연구에서 발표된 Encoder-Decoder 모델의 성능이 뛰어남\n",
    "---\n",
    "### 2-1. RNN encoder-Decoder\n",
    "일반적인 RNN encoder-decoder 모델\n",
    "1. Encoder는 입력문장을 읽고 벡터로 변환한다.\n",
    "    - 입력문장 ${\\bf x} = ( x_1, \\cdots , x_{Tx} )$을 벡터 $c$로 변환\n",
    "    - 은닉층 $h_t = f(x_t, h_{t-1})$\n",
    "    - context vector $c = q(\\{ h_1, \\cdots, h_{Tx}\\})$\n",
    "    - $f, \\space q$는 비선형 함수를 사용한다.\n",
    "2. Decoder는 다음 단어  $y_{t'}$를 예측하기위해 훈련된다.\n",
    "    - 입력으로 Encoder에서 생성된 벡터 $c$와 직전에 생성된 단어들 $\\{y_1, \\cdots, y_{t'-1}\\}$을 받는다.\n",
    "    - 즉, decoder는  결합 확률(joint probability)을 순차적인 조건부 확률(ordered conditionals)로 분해함으로써 번역 $\\bf y$에 대한 확률을 정의한다.\n",
    "        - 식:  $p({\\bf y}) = \\prod_{t=1}^Tp(y_t|\\{y_1, \\cdots, y_{t-1}\\}, \\space c)$ $\\cdots$ (Equation.②)\n",
    "        - $\\bf y$는 입력 벡터들의 sequence임.\n",
    "    - RNN에서 조건부 확률은 $p(y_t|\\{y_1, \\cdots, y_{t-1}\\}, \\space c) = g(y_{t-1}, s_t, c) \\space \\cdots$ (Equation.③)로 모델링 될 수 있다.\n",
    "        - $g$는 다층으로 형성된 비선형 함수이고 $y_t$에 대한 확률을 계산하는 함수다.\n",
    "        - $s_t$는 RNN의 은닉 상태의 벡터다.\n",
    "        - 꼭 RNN이 아니어도 다른 구조들도 사용될 수 있다.(de-convolution neural network 같은 것들)\n",
    "---\n",
    "## 3. Learning to Align and Translation\n",
    "- 본 연구에서 제안하는 새로운 NMT구조에 대해 설명한다.\n",
    "    1. BiRNN(Encoder)\n",
    "    2. Decoding 시에 source sentence에 attention\n",
    "\n",
    "### 3-1. Decoder: General Description\n",
    "- Attention mechanism을 사용하여 Encoder에서 source sentence의 모든 정보를 하나의 고정된 길이의 벡터로 바꿔야 하는 짐을 덜어주었다.\n",
    "- 기존의 모델에서는 하나의 context vector $c$\n",
    "- 하지만 본 연구가 제시한 모델에서는 **예측할(번역할) 각 단어$y_i$에 대하여 구별되는 맥락 벡터(context vector) $c_i$를 사용**\n",
    "    - $c_i$는 Encoder가 매핑하는 입력 문장에 대한 annotation squence에 따라 달라진다.\n",
    "        - annotation: $(h_1,\\cdots,h_{Tx})$ 각각의 $h_i$는 입력 문장의 $i$번째 단어를 둘러싼 부분에 집중(focus)하여 전체 입력 시퀀스에 대한 정보를 포함.\n",
    "    - 예측할 단어 $y_i$에 대한 context vector $c_i$는 annotation들과의 가중 합으로 계산. \n",
    "        - $c_i = \\sum_{j=1}^{T_x}\\alpha_{ij}h_j$ << expected annotation(모든 annotation들의 가중합)\n",
    "        - $\\alpha_{ij} = {\\exp(e_{ij})\\over\\sum_{k=1}^{T_x}\\exp(e_{ik})}$ << 가중치\n",
    "        - $e_{ij} = a(s_{i-1}, h_j)$ << $h_j$의 중요도를 반영하는 값\n",
    "            - $s_i$는 RNN에서 $i$번째 time step의 은닉 상태\n",
    "            - $h_j$는 $j$번째 annotation\n",
    "---\n",
    "### 3-2. Encoder: BiRNN for annotation sequences\n",
    "- annotation sequences가 어떻게 계산되는지에 대해 설명한다.\n",
    "1. Forward RNN 은 입력 시퀀스를 순서대로 ($x_1$부터 $x_{Tx}$까지) 읽고 ***forward hidden state($\\overrightarrow h_1, \\cdots, \\overrightarrow h_{Tx}$)***를 계산한다.\n",
    "2. Backward RNN은 입력 시퀀스를 반대 순서로($x_{Tx}$부터 $x_1$까지) 읽고 ***backward hidden state(***$\\overleftarrow h_1, \\cdots, \\overleftarrow h_{Tx}$***)***를 계산한다.\n",
    "3. 마지막으로 $x_j$에 대한 *annotation($h_j$)*은 **forward와 backward의 concat**을 통해 얻을 수 있다. 즉, $h_j =$  $[\\overrightarrow h_j^T ; \\overleftarrow h_j^T]$이다.\n",
    "    - 두 개의 행벡터를 쌓았다고 생각하자.\n",
    "    - (벡터는 기본적으로 열벡터 표현이고, transpose했으니까 행벡터)\n",
    "    - 세미콜론은 일반적으로 행의 끝을 의미,,\n",
    "- 따라서 $h_j$라는 annotation은 앞 뒤 단어 모두에 대한 요약을 담고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6e5398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsrl\\AppData\\Local\\Temp\\ipykernel_2960\\2135415625.py:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(attn_scores).view(1, 1, -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0040 cost = 0.014486\n",
      "Epoch: 0080 cost = 0.004102\n",
      "Epoch: 0120 cost = 0.002566\n",
      "Epoch: 0160 cost = 0.001766\n",
      "Epoch: 0200 cost = 0.001306\n",
      "Epoch: 0240 cost = 0.001012\n",
      "Epoch: 0280 cost = 0.000811\n",
      "Epoch: 0320 cost = 0.000666\n",
      "Epoch: 0360 cost = 0.000558\n",
      "Epoch: 0400 cost = 0.000475\n",
      "Epoch: 0440 cost = 0.000410\n",
      "Epoch: 0480 cost = 0.000358\n",
      "Epoch: 0520 cost = 0.000315\n",
      "Epoch: 0560 cost = 0.000280\n",
      "Epoch: 0600 cost = 0.000251\n",
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsrl\\AppData\\Local\\Temp\\ipykernel_2960\\2135415625.py:118: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
      "C:\\Users\\alsrl\\AppData\\Local\\Temp\\ipykernel_2960\\2135415625.py:119: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code by Tae Hwan Jung @graykode\n",
    "# Reference : https://github.com/hunkim/PyTorchZeroToAll/blob/master/14_2_seq2seq_att.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "\n",
    "def make_batch():\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "\n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
    "\n",
    "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
    "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_outputs : [n_step, batch_size, num_directions(=1) * n_hidden], matrix F\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)\n",
    "\n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden\n",
    "        n_step = len(dec_inputs)\n",
    "        model = torch.empty([n_step, 1, n_class])\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1))\n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
    "\n",
    "        # make model shape [n_step, n_class]\n",
    "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
    "\n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        n_step = len(enc_outputs)\n",
    "        attn_scores = torch.zeros(n_step)  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return F.softmax(attn_scores).view(1, 1, -1)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
    "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n_step = 5 # number of cells(= number of Step)\n",
    "    n_hidden = 128 # number of hidden units in one cell\n",
    "\n",
    "    sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "    word_list = \" \".join(sentences).split()\n",
    "    word_list = list(set(word_list))\n",
    "    word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "    number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "    n_class = len(word_dict)  # vocab list\n",
    "\n",
    "    # hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "    hidden = torch.zeros(1, 1, n_hidden)\n",
    "\n",
    "    model = Attention()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    input_batch, output_batch, target_batch = make_batch()\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(600):\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "        loss = criterion(output, target_batch.squeeze(0))\n",
    "        if (epoch + 1) % 40 == 0:\n",
    "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test\n",
    "    test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
    "    test_batch = torch.FloatTensor(test_batch)\n",
    "    predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "    predict = predict.data.max(1, keepdim=True)[1]\n",
    "    print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n",
    "\n",
    "    # Show Attention\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(trained_attn, cmap='gray')\n",
    "    ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "    ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43e923",
   "metadata": {},
   "source": [
    "### 코드 뜯어보기 ① make_batch\n",
    "```python \n",
    "def make_batch():\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "```\n",
    "- input_batch 하나에 대해서 이해하면 output_batch도 똑같은 방식으로 이해 할 수 있다.\n",
    "    - 먼저 np.eye(n)은 n x n identity matrix를 만든다.\n",
    "    - 그 뒤에 대괄호로 인덱싱을 해주는 형식이다.\n",
    "        - 그 인덱싱은 ```[word_dict[n] for n in sentences[0].split()]```이다. \n",
    "        - word_dict는 아마 단어가 숫자(index)와 함께 저장되어있는 dictionary이다.\n",
    "        - 문장을 split()했으니 띄어쓰기로 나누었으므로 n은 하나의 단어가 된다.\n",
    "    - 대충 예를 들어 생각해보면 np.eye(5)[[0, 1, 2, 3]]뭐 이런 형식이다.\n",
    "        - 처음엔 이게 인덱싱이 되나 했지만, 된다.\n",
    "        - 행, 열 인덱스를 동시에 주지 않으면 일단 '행'기준이라 생각하자\n",
    "        - 따라서 5 x 5 항등행렬의 1, 2, 3, 4 행을 가져온다.\n",
    "- output_batch도 마찬가지로 생각하자.\n",
    "--- \n",
    "```python\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
    "```\n",
    "- target_batch는 그냥 리스트안에 리스트가 있는 형식이다.\n",
    "- return에서 전부 torch.Tensor형태로 바꿔준다.\n",
    "    - Tensor 형태에 대해서는 [여기](https://pytorch.org/docs/stable/tensors.html)를 클릭\n",
    "    - Float는 32-bit float, Long은 64-bit integar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd4ea59",
   "metadata": {},
   "source": [
    "### 코드 뜯어보기 ② class Attention, __init __\n",
    "```python\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "\n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
    "```\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725574fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "word_dict ={'ich':0, 'mochte':1, 'ein':2, 'bier':3, 'P':4}\n",
    "inputs = [np.eye(5)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e193ed0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[word_dict[n] for n in sentences[0].split()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af0e99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(5)[[1, 2, 3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a66afb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.63724063 -0.51011509 -0.52261814  1.42182023]\n",
      " [ 0.8045689   2.29169468  1.68847911 -0.3652619 ]\n",
      " [-1.21349768  0.73995342  0.12097152  1.37670112]]\n",
      "[[-0.51011509 -0.52261814]\n",
      " [ 2.29169468  1.68847911]\n",
      " [ 0.73995342  0.12097152]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(3, 4)\n",
    "print(a)\n",
    "print(a[ :, [1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31adfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp1",
   "language": "python",
   "name": "nlp1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov  4 2022, 13:42:51) [MSC v.1916 64 bit (AMD64)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
